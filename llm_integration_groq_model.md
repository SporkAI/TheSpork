# LLM Integration: GROQ Model

## Model Selection and Rationale

The GROQ-based LLM is fast, parallelized, and ideal for real-time chat. It balances speed and coherence for lively, data-driven conversations.

## Training and Fine-Tuning

- **Domain-Specific Data:** Crypto-centric training for jargon, trends, and community slang.
- **Behavioral Conditioning:** Humorous prompts shape a friendly, witty personality.
- **Ongoing Refinement:** Continual updates reflect evolving markets and user feedback.

## Context Handling and Memory

- **Short-Term Context:** Maintains recent chat history for coherent multi-turn conversations.
- **Long-Term Memory:** Stores key facts and preferences externally, re-injecting as needed.
